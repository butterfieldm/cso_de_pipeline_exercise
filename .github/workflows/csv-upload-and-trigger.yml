# YAML file to upload new CSV files in the local data/ folder to specified GCS bucket

# .github/workflows/csv-upload-and-trigger.yml

name: Upload CSVs and Trigger Dataflow

on:
  push:
    branches:
      - main
    paths:
      - 'data/**'
      - 'schemas/**'
  workflow_dispatch:

jobs:
  upload-and-trigger:
    runs-on: ubuntu-latest

    env:
      BUCKET_NAME: cso-exercise-ingestion-raw
      PROJECT_ID: cso-deng-pipeline
      REGION: europe-west2
      TOPIC_NAME: gcs-file-drop-topic
      SUBSCRIPTION_NAME: gcs-upload-sub

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate with GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_PROJECT_KEY }}

      - name: Confirm Auth Context
        run: |
          gcloud auth list
          gcloud config list
      
      - name: Upload schema files
        run: |
          gsutil -m cp -r schemas/ gs://cso-exercise-ingestion-raw/
        

      - name: Upload CSVs to GCS
        uses: google-github-actions/upload-cloud-storage@v1
        with:
          path: data/
          destination: ${{ env.BUCKET_NAME }}/
          parent: false
          process_gcloudignore: false 

      - name: Confirm Upload Triggered Notification
        run: |
          echo "Listing latest messages received by Pub/Sub topic (if logging is enabled)..."
          echo "NOTE: This won't show content unless logging or debug sinks are configured."
